{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "\n",
    "def project_dir():\n",
    "    notebook_path = %pwd\n",
    "    repo_name = \"sisi\"\n",
    "    repo_folder = notebook_path.split(repo_name)[0]\n",
    "    return os.path.join(repo_folder, repo_name)\n",
    "\n",
    "\n",
    "pwd = os.getenv(\"PWD\", project_dir())\n",
    "os.environ[\"PWD\"] = pwd\n",
    "sys.path.append(pwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.data_utils import get_data_and_state_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dense_model(layers: List[int], output_len: int):\n",
    "    \n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    for units in layers:\n",
    "        model.add(tf.keras.layers.Dense(units=units))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(units=output_len*1))\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def generate_data(df: pd.DataFrame, input_len: int, output_len: int, x_cols: List[str], y_cols: List[str], val_ratio: float):\n",
    "    \n",
    "    data_X = df.loc[:, x_cols].to_numpy().reshape(-1, len(x_cols))\n",
    "    data_y = df.loc[:, y_cols].to_numpy().reshape(-1, len(y_cols))\n",
    "    \n",
    "    # maybe later :)\n",
    "    # data_X = (data_X - data_X.mean(axis=0)) / data_X.std(axis=0)\n",
    "    # data_y = (data_y - data_y.mean(axis=0)) / data_y.std(axis=0)\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(input_len, data_X.shape[0]-output_len):\n",
    "        inp = data_X[i-input_len:i, :]\n",
    "        out = data_y[i:i+output_len, :]\n",
    "        X.append(inp)\n",
    "        y.append(out)\n",
    "\n",
    "    X = np.array(X).reshape(-1, input_len, len(x_cols))\n",
    "    y = np.array(y).reshape(-1, output_len, len(y_cols))\n",
    "    \n",
    "    val_len = int(val_ratio * X.shape[0])\n",
    "    train_X = X[:-val_len, ...]\n",
    "    train_y = y[:-val_len, ...]\n",
    "    val_X = X[-val_len:, ...]\n",
    "    val_y = y[-val_len:, ...]\n",
    "    \n",
    "    return (train_X, train_y), (val_X, val_y)\n",
    "\n",
    "\n",
    "\n",
    "def plot_history(history: tf.keras.callbacks.History):\n",
    "    f, ax = plt.subplots(2, 1, figsize=(16,8))\n",
    "    ax[0].plot(history.history[\"loss\"], label=\"train\")\n",
    "    ax[0].plot(history.history[\"val_loss\"], label=\"val\")\n",
    "    ax[0].set_title(\"MSE Loss\")\n",
    "    ax[0].legend()\n",
    "    ax[1].plot(history.history[\"mean_absolute_error\"], label=\"train\")\n",
    "    ax[1].plot(history.history[\"val_mean_absolute_error\"], label=\"val\")\n",
    "    ax[1].set_title(\"MAE Loss\")\n",
    "    ax[1].legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def compile_and_fit(model: tf.keras.Model, X: np.ndarray, y: np.ndarray, val: Tuple[np.ndarray], max_epochs: int = 20, patience: int = 2, verbose: int = 0):\n",
    "\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience, mode='min', restore_best_weights=True)\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "    history = model.fit(X, y, epochs=max_epochs, batch_size=4, validation_data=val, callbacks=[early_stopping], verbose=verbose)\n",
    "    \n",
    "    return history\n",
    "\n",
    "\n",
    "\n",
    "def fit_dense(input_len: int, output_len: int, layers: List[int],\n",
    "             df: pd.DataFrame, x_cols: List[str] = ..., y_cols: List[str] = ..., val_ratio: float = 0.2,\n",
    "             max_epochs: int = 20, patience: int = 2, verbose: int = 0):\n",
    "    \n",
    "    if x_cols is Ellipsis:\n",
    "        x_cols = [\"carbon_per_MWh\", \"day_sin\", \"day_cos\", \"year_sin\", \"year_cos\"]\n",
    "    if y_cols is Ellipsis:\n",
    "        y_cols = [\"carbon_per_MWh\"]\n",
    "    \n",
    "    dense = generate_dense_model(layers=layers, output_len=output_len)\n",
    "    \n",
    "    (X, y), (val_X, val_y) = generate_data(df=df, input_len=input_len, output_len=output_len, x_cols=x_cols, y_cols=y_cols, val_ratio=val_ratio)\n",
    "    X = X.reshape(X.shape[0], -1)\n",
    "    y = y.reshape(y.shape[0], -1)\n",
    "    val_X = val_X.reshape(val_X.shape[0], -1)\n",
    "    val_y = val_y.reshape(val_y.shape[0], -1)\n",
    "    print([a.shape for a in (X, y, val_X, val_y)])\n",
    "\n",
    "    history = compile_and_fit(model=dense, X=X, y=y, val=(val_X, val_y), max_epochs=max_epochs, patience=patience, verbose=verbose)\n",
    "    plot_history(history=history)\n",
    "    \n",
    "    return_obj = {\n",
    "        \"model\": dense,\n",
    "        \"history\": history,\n",
    "        \"hp\": {\n",
    "            \"input_len\": input_len,\n",
    "            \"output_len\": output_len,\n",
    "            \"layers\": layers,\n",
    "            \"x_cols\": x_cols,\n",
    "            \"y_cols\": y_cols,\n",
    "            \"val_ratio\": val_ratio,\n",
    "            \"max_epochs\": max_epochs,\n",
    "            \"patience\": patience\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return return_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list, state_list = get_data_and_state_list(pwd=\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "\n",
    "day_hours = 24 * 60 * 60\n",
    "year_hours = 365.2425 * day_hours\n",
    "\n",
    "input_len = 7 * 24\n",
    "output_len = 24\n",
    "layers = [256, 64, 32]\n",
    "max_epochs = 50\n",
    "patience = 5\n",
    "\n",
    "\n",
    "# getting predictions\n",
    "\n",
    "preds_list = []\n",
    "\n",
    "for df, state in zip(df_list, state_list):\n",
    "    \n",
    "    print(f\"\\n\\n==== {state} ====\")\n",
    "    \n",
    "    # dataframe preparation\n",
    "    \n",
    "    df.datetime = pd.to_datetime(df.datetime)\n",
    "    timestamp_s = df.datetime.map(dt.datetime.timestamp)\n",
    "\n",
    "    df['day_sin'] = np.sin(timestamp_s * (2 * np.pi / day_hours))\n",
    "    df['day_cos'] = np.cos(timestamp_s * (2 * np.pi / day_hours))\n",
    "    df['year_sin'] = np.sin(timestamp_s * (2 * np.pi / year_hours))\n",
    "    df['year_cos'] = np.cos(timestamp_s * (2 * np.pi / year_hours))\n",
    "\n",
    "    df = df.fillna(value=0)\n",
    "\n",
    "    df_train = df.loc[df.datetime.dt.year < 2022]\n",
    "\n",
    "\n",
    "    # training model\n",
    "\n",
    "    week2day = fit_dense(input_len=input_len, output_len=output_len, layers=layers, df=df_train, max_epochs=max_epochs, patience=patience, verbose=1)\n",
    "\n",
    "\n",
    "    # generating predictions\n",
    "    \n",
    "    model = week2day[\"model\"]\n",
    "    hp = week2day[\"hp\"]\n",
    "    input_len = hp[\"input_len\"]\n",
    "    output_len = hp[\"output_len\"]\n",
    "    x_cols = hp[\"x_cols\"]\n",
    "    y_cols = hp[\"y_cols\"]\n",
    "\n",
    "    df_test = df.loc[(df.datetime + dt.timedelta(hours=hp[\"input_len\"])).dt.year >= 2022]\n",
    "    data_X = df_test.loc[:, x_cols].to_numpy()\n",
    "\n",
    "    test_X = []\n",
    "    for i in range(input_len, data_X.shape[0], output_len):\n",
    "        inp = data_X[i-input_len:i, ...].ravel()\n",
    "        test_X.append(inp)\n",
    "\n",
    "    test_X = np.array(test_X)\n",
    "    \n",
    "    \n",
    "    # saving predictions to dict\n",
    "    \n",
    "    timestamps = df.loc[df.datetime.dt.year >= 2022, \"datetime\"]\n",
    "    preds = model.predict(test_X).ravel()\n",
    "    preds_dict = {t: p for t, p in zip(timestamps, preds)}\n",
    "    \n",
    "    preds_list.append(preds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/predictions/dnn_pred_usa.pkl\", \"wb\") as f:\n",
    "    pickle.dump(preds_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
